function [mix, options, errlog] = gmmLINem(mix,mix2, x,W,indZeroLinCoef, options)
%GMMEM	EM algorithm for Gaussian mixture model.
%
%	Description
%	[MIX, OPTIONS, ERRLOG] = GMMEM(MIX, X, OPTIONS) uses the Expectation
%	Maximization algorithm of Dempster et al. to estimate the parameters
%	of a Gaussian mixture model defined by a data structure MIX. The
%	matrix X represents the data whose expectation is maximized, with
%	each row corresponding to a vector.    The optional parameters have
%	the following interpretations.
%
%	OPTIONS(1) is set to 1 to display error values; also logs error
%	values in the return argument ERRLOG. If OPTIONS(1) is set to 0, then
%	only warning messages are displayed.  If OPTIONS(1) is -1, then
%	nothing is displayed.
%
%	OPTIONS(3) is a measure of the absolute precision required of the
%	error function at the solution. If the change in log likelihood
%	between two steps of the EM algorithm is less than this value, then
%	the function terminates.
%
%	OPTIONS(5) is set to 1 if a covariance matrix is reset to its
%	original value when any of its singular values are too small (less
%	than MIN_COVAR which has the value eps).   With the default value of
%	0 no action is taken.
%
%	OPTIONS(14) is the maximum number of iterations; default 100.
%
%	The optional return value OPTIONS contains the final error value
%	(i.e. data log likelihood) in OPTIONS(8).
%
%	See also
%	GMM, GMMINIT
%

%	Copyright (c) Ian T Nabney (1996-2001)

debug = 1;


% Check that inputs are consistent
errstring = consist(mix, 'gmm', x);
if ~isempty(errstring)
  error(errstring);
end

[ndata, xdim] = size(x);
NbW           = size(W(1).w,2); 

%% pre-compute wtw
for jj = 1:mix.ncentres
  for i=1:ndata
    W(jj).wtwi     = W(jj).w(i,:)' * W(jj).w(i,:);
    W(jj).wtw(i,:) = W(jj).wtwi(:)';
  end
end

% Sort out the options
if (options(14))
  niters = options(14);
else
  niters = 100;
end

display = options(1);
store = 0;
if (nargout > 2)
  store = 1;	% Store the error values to return them
  errlog = zeros(1, niters);
end
test = 0;
if options(3) > 0.0
  test = 1;	% Test log likelihood for termination
end

check_covars = 0;
if options(5) >= 1
  if display >= 0
    disp('check_covars is on');
  end
  check_covars = 1;	% Ensure that covariances don't collapse
  MIN_COVAR = eps;	% Minimum singular value of covariance matrix
  init_covars = mix.covars;
end

% Main loop of algorithm
for n = 1:niters
  
  % Calculate posteriors based on old parameters
  [post, act] = gmmLIN2post(mix,mix2, x,W);
  %[post, act] = gmmpost(mix2,x);
  
  % Calculate error value if needed
  if (display | store | test)
    prob = act*(mix.priors)';
    % Error value is negative log likelihood of data
    e = - sum(log(prob));
    if store
      errlog(n) = e;
    end
    if display > 0
      fprintf(1, 'Cycle %4d  Error %11.6f\n', n, e);
    end
    if test
      if (n > 1 & abs(e - eold) < options(3))
        options(8) = e;
        return;
      else
        eold = e;
      end
    end
  end
  
  % Adjust the new estimates for the parameters
  new_pr = sum(post, 1);
  new_c = post' * x;
  
  % Now move new estimates to old parameter vectors
  %% priors
  mix.priors = new_pr ./ ndata;
  
  %% "mean" model
  wAtY = zeros(mix.ncentres,1);
  for j = 1:mix.ncentres
    wAtA = reshape( sum( (post(:,j)*ones(1,NbW*NbW)) .* W(j).wtw , 1) ,[NbW NbW]);
    wAtY = (post(:,j)*ones(1,size(x,2)) .* x)' * W(j).w;
% $$$     wAtA = reshape( sum( ((post(:,j) > 0.3)*ones(1,9)) .* wtw , 1) ,[3 3]);  %% pour verification
% $$$     wAtY = ((post(:,j) > 0.3) .* x)' * w;
% $$$     wAtA2 = zeros(3,3);
% $$$     for i = 1:ndata
% $$$       wAtA2 = wAtA2 + post(i,j)* w(i,:)'*w(i,:);
% $$$     end
% $$$     A = max((wAtA(:)-wAtA2(:)).^2)
    
    mix.centres(j).c = (pinv(wAtA) * wAtY')'; 
    %mix.centres(j).c = [0 0 mix.centres(j).c(1,3);0 0 mix.centres(j).c(2,3)];
    
    
    %% forcing to zeros: linear coeff
    mix.centres(j).c(indZeroLinCoef) = 0;
    mix.centres(j).c
   
    if debug
      clf(figure(100));
      figure(100);
      ind = find( post(:,j) > 0.8 );
      xpred = (mix.centres(j).c * W(j).w(ind,:)')';
      subplt(311);plot(x(ind,1),x(ind,2),'b*');
      subplot(312);hold on;
      plot(W(j).w(ind,1),x(ind,1),'r*');
      plot(W(j).w(ind,1),xpred(:,1),'b*');
      subplot(313);hold on;
      plot(W(j).w(ind,2),x(ind,2),'r*');
      plot(W(j).w(ind,2),xpred(:,2),'b*');
      pause;
    end
  
  end
  
  %% covariance
  for jj = 1:mix.ncentres
    diffs = x - (mix.centres(jj).c * W(jj).w')';
    %diffs = x - ones(size(x,1),1)*mix.centres(jj).c(:,3)';
    %v(j)  = (post(:,j).* diffs)'*diffs; %% modif rfablet 27/11/2009
    covj    = ((post(:,jj)*ones(1,2)).* diffs)'*diffs;
    %v(jj,:) = sum(((post(:,jj)*ones(1,2)).* diffs).*diffs,1);
    
    v(jj,:)  = diag( covj );  %% modif rfablet 27/11/2009
  end
  mix.covars = v./ (new_pr' * ones(1,xdim) );
  mix.covars
  pause;
end

options(8) = -sum(log(gmmLINprob(mix, x, w)));
if (display >= 0)
  disp(maxitmess);
end
  